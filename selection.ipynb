{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.configure import get_rerank_config\n",
    "from core.models import TypeCLSModel\n",
    "from core.datasets.selection import get_typecls_datasets\n",
    "from core.evaluate import evalacc,evalf1,evalNumAcc\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args,logger = get_rerank_config()\n",
    "data_list=get_typecls_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(save_path, epoch, best_accuracy, optimizer, model):\n",
    "    torch.save({'epoch': epoch+1,\n",
    "                'best_accuracy': best_accuracy,\n",
    "                'optimizer_dict': optimizer.state_dict(),\n",
    "                'model_dict': model.state_dict()}, save_path)\n",
    "\n",
    "\n",
    "def cleanup_state_dict(state_dict):\n",
    "    new_state = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if \"module\" in k:\n",
    "            new_name = k[7:]\n",
    "        else:\n",
    "            new_name = k\n",
    "        new_state[new_name] = v\n",
    "    return new_state\n",
    "\n",
    "\n",
    "def load_model(save_name, model,optimizer):\n",
    "    model_data = torch.load(save_name)\n",
    "#     print(model_data['model_dict'])\n",
    "    model.load_state_dict(cleanup_state_dict(model_data['model_dict']))\n",
    "    optimizer.load_state_dict(cleanup_state_dict(model_data['optimizer_dict']))\n",
    "    best_accuracy = model_data['best_accuracy']\n",
    "    print(best_accuracy)\n",
    "    print(\"model load success\")\n",
    "    return model,optimizer,best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_n_evaluate(model,loss_fn, optimizer, evaluate, tokenizer, best_f1=0,best_acc = 0):\n",
    "    step = 0\n",
    "    best_acc = best_acc\n",
    "    best_f1 = best_f1\n",
    "    train_dataset = data_list[\"train\"]\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size)\n",
    "    # dev_dataset = Dataset(X_dev, y_dev, flag='dev')\n",
    "    # dev_dataloader = DataLoader(dev_dataset, batch_size=args.batch_size)\n",
    "    # test_dataset = Dataset(X_test,y_test,flag='test')\n",
    "    # test_dataloader = DataLoader(test_dataset, batch_size=args.batch_size)\n",
    "    for epoch in range(args.epoch_nums):\n",
    "        model.train()\n",
    "        logger.info('#'*20 + 'Epoch{}'.format(epoch) + '#'*20)\n",
    "        loop = tqdm(train_dataloader, desc=f'Training Epoch {epoch}')\n",
    "        epoch_loss = []\n",
    "        for X1,X2,X3,X4, y in loop:\n",
    "            # print(y)\n",
    "            X1_cuda = {}\n",
    "            for i in X1:\n",
    "                X1_cuda[i] = X1[i].cuda()\n",
    "            X2_cuda = {}\n",
    "            for i in X2:\n",
    "                X2_cuda[i] = X2[i].cuda()\n",
    "            X3_cuda = {}\n",
    "            for i in X3:\n",
    "                X3_cuda[i] = X3[i].cuda()\n",
    "            X4_cuda = {}\n",
    "            for i in X4:\n",
    "                X4_cuda[i] = X4[i].cuda()\n",
    "            y_cuda = y.cuda()\n",
    "            # X_cuda = [x.cuda(5) for x in X]\n",
    "            # input_ids, attention_mask, position_ids = X\n",
    "\n",
    "            # # print(X_cuda['input_ids'])\n",
    "            y_pred = model(X1_cuda,X2_cuda,X3_cuda,X4_cuda).squeeze()\n",
    "            loss = loss_fn(y_pred, y_cuda.float())\n",
    "            epoch_loss.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loop.set_postfix(loss=f'Train loss: {loss:.6f}')\n",
    "            # writer.add_scalar(tag='Train step Loss', scalar_value=loss, global_step=step)\n",
    "            step += 1\n",
    "        # writer.add_scalar(tag='Train Loss', scalar_value=torch.tensor(epoch_loss).mean(), global_step=epoch)\n",
    "            # # print(y_pred,y)\n",
    "        save_model(args.model_path+\"last_\"+str(args.version)+\".pth\",\n",
    "                   epoch, best_acc, optimizer, model)\n",
    "        acc, f1 = evaluate(model,tokenizer)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            save_model(args.model_path+\"best_acc_\"+str(args.version)+\".pth\",\n",
    "                       epoch, best_acc, optimizer, model)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            save_model(args.model_path+\"best_f1_\"+str(args.version)+\".pth\",\n",
    "                       epoch, best_f1, optimizer, model)\n",
    "        # write_result(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, tokenizer):\n",
    "    # gold = json.load(open(\"/mnt/data/smart_health_02/zhuyansha/data/CHIP-CDN-SR/recall_top20/dev.json\",\"r\"))\n",
    "    test_dataset = data_list[\"dev\"]\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=args.batch_size)\n",
    "    model.eval()\n",
    "    pred_dict = {}\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(test_dataloader, desc='Evaluating')\n",
    "        y_preds = []\n",
    "        y_trues = []\n",
    "        # tmp_y_pred = []\n",
    "        # current_item = \"\"\n",
    "        Xs = []\n",
    "        ys = []\n",
    "        for X1,X2,X3,X4, y in loop:\n",
    "            X1_cuda = {}\n",
    "            for i in X1:\n",
    "                X1_cuda[i] = X1[i].cuda()\n",
    "            X2_cuda = {}\n",
    "            for i in X2:\n",
    "                X2_cuda[i] = X2[i].cuda()\n",
    "            X3_cuda = {}\n",
    "            for i in X3:\n",
    "                X3_cuda[i] = X3[i].cuda()\n",
    "            X4_cuda = {}\n",
    "            for i in X4:\n",
    "                X4_cuda[i] = X4[i].cuda()\n",
    "            # y_cuda = y.cuda()\n",
    "            # X_cuda = [x.cuda(5) for x in X]\n",
    "            # input_ids, attention_mask, position_ids = X\n",
    "\n",
    "            # # print(X_cuda['input_ids'])\n",
    "            y_pred = model(X1_cuda,X2_cuda,X3_cuda,X4_cuda).squeeze()\n",
    "            Xs.extend(y_pred)\n",
    "            ys.extend(y)\n",
    "\n",
    "        for X, y in zip(Xs,ys):\n",
    "            mention = y.split(\"###\")[0]\n",
    "            candidate = y.split(\"###\")[1]\n",
    "            # stds = y.split(\"###\")[2]\n",
    "            if mention not in pred_dict.keys():\n",
    "                pred_dict[mention] = []\n",
    "            if X > args.threshold:\n",
    "                pred_dict[mention].append(candidate)\n",
    "        # print(pred_dict)\n",
    "        for item in gold:\n",
    "            \n",
    "            tmp = []\n",
    "            for sr in item[\"SR\"]:\n",
    "                tmp.extend(pred_dict[sr])\n",
    "            tmp.extend(pred_dict[item[\"text\"]])\n",
    "            y_preds.append(list(set(tmp)))\n",
    "            y_trues.append(item[\"normalized_result\"])\n",
    "        acc, mul_acc, uni_acc = evalacc(y_preds, y_trues)\n",
    "        f1, p, r = evalf1(y_preds, y_trues)\n",
    "        num_acc=evalNumAcc(y_preds, y_trues)\n",
    "        logger.info('#'*20 + 'acc{}'.format(acc) + '#'*20)\n",
    "        logger.info('#'*20 + 'mul_acc{}'.format(mul_acc) + '#'*20)\n",
    "        logger.info('#'*20 + 'uni_acc{}'.format(uni_acc) + '#'*20)\n",
    "        logger.info('#'*20 + 'f1{}'.format(f1) + '#'*20)\n",
    "        logger.info('#'*20 + 'p{}'.format(p) + '#'*20)\n",
    "        logger.info('#'*20 + 'r{}'.format(r) + '#'*20)\n",
    "        logger.info('#'*20 + 'NumAcc{}'.format(num_acc) + '#'*20)\n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_write(model, tokenizer):\n",
    "    test_dataset = data_list[\"test\"]\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=args.batch_size)\n",
    "    model.eval()\n",
    "    pred_dict = {}\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(test_dataloader, desc='Evaluating')\n",
    "        y_preds = []\n",
    "        y_trues = []\n",
    "        Xs = []\n",
    "        ys = []\n",
    "        for X1,X2,X3,X4, y in loop:\n",
    "            X1_cuda = {}\n",
    "            for i in X1:\n",
    "                X1_cuda[i] = X1[i].cuda()\n",
    "            X2_cuda = {}\n",
    "            for i in X2:\n",
    "                X2_cuda[i] = X2[i].cuda()\n",
    "            X3_cuda = {}\n",
    "            for i in X3:\n",
    "                X3_cuda[i] = X3[i].cuda()\n",
    "            X4_cuda = {}\n",
    "            for i in X4:\n",
    "                X4_cuda[i] = X4[i].cuda()\n",
    "            # y_cuda = y.cuda()\n",
    "            # X_cuda = [x.cuda(5) for x in X]\n",
    "            # input_ids, attention_mask, position_ids = X\n",
    "\n",
    "            # # print(X_cuda['input_ids'])\n",
    "            y_pred = model(X1_cuda,X2_cuda,X3_cuda,X4_cuda).squeeze()\n",
    "            Xs.extend(y_pred)\n",
    "            ys.extend(y)\n",
    "\n",
    "        for X, y in zip(Xs,ys):\n",
    "            mention = y.split(\"###\")[0]\n",
    "            candidate = y.split(\"###\")[1]\n",
    "            # stds = y.split(\"###\")[2]\n",
    "            if mention not in pred_dict.keys():\n",
    "                pred_dict[mention] = []\n",
    "            if X > args.threshold:\n",
    "                pred_dict[mention].append(candidate)\n",
    "        return pred_dict\n",
    "def write_result(i):\n",
    "    pred_dict = predict_write(model, tokenizer)\n",
    "    with open(\"data/origin_data/CHIP-CDN_test.json\",\"r\",encoding='utf-8') as f:\n",
    "        original_data = json.load(f)\n",
    "    result_list = []\n",
    "    for item in original_data:\n",
    "        tmp = []\n",
    "        for sr in item[\"SR\"]:\n",
    "            tmp.extend(pred_dict[re.sub('\\[.*?\\]','',sr)])\n",
    "        tmp.extend(pred_dict[item[\"text\"]])\n",
    "        \n",
    "        result_list.append({\n",
    "        \"text\":item['text'],\n",
    "        \"normalized_result\":\"##\".join(list(set(tmp)))\n",
    "        })\n",
    "        # item['normalized_result'] = mentions2preds[item['text'].replace('\"','').replace('?','')] if item['text'].replace('\"','').replace('?','') in mentions2preds.keys() else \"\"\n",
    "    with open(args.output_path+\"CHIP-CDN_test\"+str(i)+\".json\",\"w\",encoding='utf-8') as f:\n",
    "        f.write(json.dumps(result_list,ensure_ascii=False, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TypeCLSModel()\n",
    "# model,optimizer,best_f1 = load_model(args.model_path+\"best_f1_\"+str(args.version)+\".pth\",model,optimizer)\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=args.learning_rate)\n",
    "model.cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.plm_name)\n",
    "best_f1 = 0\n",
    "train_n_evaluate(model,\n",
    "                 loss_fn, optimizer, evaluate, tokenizer,best_f1=best_f1)\n",
    "model,optimizer,best_f1 = load_model(args.model_path+\"best_f1_\"+str(args.version)+\".pth\",model,optimizer)\n",
    "write_result(args.version)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "944688a44db6320333703092cfd4965318d536521f39d5d7e33d73a40c4f352e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
